{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c59e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swamp\\OneDrive\\Escritorio\\CatchAI\\catchAI\\lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb86f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_pdf(pdf):\n",
    "    reader = PdfReader(pdf)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def pdf_to_txt(text, pdf_name):\n",
    "    with open(f\"pdf/{pdf_name}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)\n",
    "    print(f\"Texto guardado en pdf/{pdf_name}.txt\")\n",
    "    return text\n",
    "\n",
    "def read_text(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1612ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: pdf\\Conceptos y temas claves.pdf\n",
      "Texto guardado en pdf/Conceptos y temas claves.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pypdf import PdfReader\n",
    "\n",
    "pdf_dir = \"pdf\"\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "for file_name in pdf_files:\n",
    "    file_path = os.path.join(pdf_dir, file_name)\n",
    "    print(f\"Procesando: {file_path}\")\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() or \"\"\n",
    "    pdf_name = os.path.splitext(file_name)[0]\n",
    "    pdf_to_txt(text, pdf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e62804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "txt_dir = \"pdf\"\n",
    "txt_files = [f for f in os.listdir(txt_dir) if f.lower().endswith(\".txt\")]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=750,\n",
    "    chunk_overlap=int(750*0.15),\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "all_chunks = []\n",
    "all_chunk_ids = []\n",
    "\n",
    "for file_name in txt_files:\n",
    "    file_path = os.path.join(txt_dir, file_name)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    chunks = text_splitter.create_documents([text])\n",
    "    for idx, doc in enumerate(chunks):\n",
    "        chunk_id = f\"{file_name}_chunk{idx+1}\"\n",
    "        all_chunks.append(doc.page_content)\n",
    "        all_chunk_ids.append(chunk_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d84bdcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swamp\\AppData\\Local\\Temp\\ipykernel_24644\\428911517.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "d:\\CatchAI\\catchAI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "all_vectors = embeddings.embed_documents(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec30a16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "C:\\Users\\swamp\\AppData\\Local\\Temp\\ipykernel_24644\\2151559639.py:10: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "# Guardar en base vectorial Chroma\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_texts(\n",
    "    all_chunks,\n",
    "    embeddings,\n",
    "    ids=all_chunk_ids,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3501ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte la consulta en embedding\n",
    "user_query = \"¿Qué experiencia tiene Tomas en Python?\"\n",
    "query_vector = embeddings.embed_query(user_query)\n",
    "\n",
    "# Busca los chunks más similares en Chroma\n",
    "results = vectorstore.similarity_search_by_vector(query_vector, k=5)\n",
    "\n",
    "relevant_chunks = [\n",
    "    result.page_content for result in results\n",
    "    if \"Python\" in result.page_content or \"programación\" in result.page_content\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4461abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join(relevant_chunks)\n",
    "prompt = (\n",
    "    f\"Contexto:\\n{context}\\n\\n\"\n",
    "    f\"Pregunta:\\n{user_query}\\n\\n\"\n",
    "    \"Responde de forma clara y específica sobre la experiencia en Python.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75ba1ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexto:\n",
      "•Seidentificanáreasdemejora,comolanecesidaddeunentrenamientomásminuciosoparaelmodeloyconsiderar losvaloresentregadospor”Botometer”paraevitarfalsospositivosynegativosenlaclasificación Educación UniversidadDiegoPortales Santiago,Chile TITULADO DE INGENIERÍA CIVIL EN INFORMÁTICA Y TELECOMUNICACIONES Mar.2019-Ene.2024 •Cursosrelevantes:IA,DataScience,SistemasDistribuidos,SistemasdeProcesamientoparaBigData Habilidades Lenguajes Python,SQL,C/C++,Ruby MachineLearning/CienciadeDatos Pandas,Numpy,Scikit-learn,Tensorflow,Matplotlib BasesdeDatos PostgreSQL,SQLServer Cloud AWSS3,Docker,Git,GCP Idiomas EspañolNativo,Inglés Otros PowerBI,Unix 29 DE JULIO DE 2025 TOMÁS FUENTES ARAYA · CURRICULUM VITAE\n",
      "árbolesdedecisión.\n",
      "•Selograunaprecisióndel88%,evaluandoelimpactodecaracterísticastextualesydecomportamiento.\n",
      "•Seidentificanáreasdemejora,comolanecesidaddeunentrenamientomásminuciosoparaelmodeloyconsiderar\n",
      "losvaloresentregadospor”Botometer”paraevitarfalsospositivosynegativosenlaclasificación\n",
      "Educación\n",
      "UniversidadDiegoPortales Santiago,Chile\n",
      "TITULADO DE INGENIERÍA CIVIL EN INFORMÁTICA Y TELECOMUNICACIONES Mar.2019-Ene.2024\n",
      "•Cursosrelevantes:IA,DataScience,SistemasDistribuidos,SistemasdeProcesamientoparaBigData\n",
      "Habilidades\n",
      "Lenguajes Python,SQL,C/C++,Ruby\n",
      "MachineLearning/CienciadeDatos Pandas,Numpy,Scikit-learn,Tensorflow,Matplotlib\n",
      "BasesdeDatos PostgreSQL,SQLServer\n",
      "Cloud AWSS3,Docker,Git,GCP\n",
      "Idiomas EspañolNativo,Inglés\n",
      "Otros PowerBI,Unix\n",
      "Education UniversidadDiegoPortales Santiago,Chile BSC. iN COMPUTER SCiENCE AND ENGiNEERiNG Mar. 2019‑Jan. 2024 •Relevantcourses: ArtificialIntelligence,DataScience,DistributedSystems,BigDataProcessingSystems. Tools Languages Python,SQL,C/C++,Ruby DataScience/ML Pandas,Numpy,Scikit‑learn,TensorFlow,Matplotlib Databases PostgreSQL,SQLServer Cloud AWSS3,Docker,Git,GCP Languages Spanish,English Others PowerBI,Unix JULY 29, 2025 TOMÁS FUENTES A. · RESUME\n",
      "\n",
      "Pregunta:\n",
      "¿Qué experiencia tiene Tomas en Python?\n",
      "\n",
      "Responde de forma clara y específica sobre la experiencia en Python.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fabaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catchAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
